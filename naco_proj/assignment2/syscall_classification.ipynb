{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a11a79c",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8308931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212857ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "snd_cert_path = \"./data/syscalls/snd-cert\"\n",
    "snd_unm_path = \"./data/syscalls/snd-unm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa9bb9",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10032a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "snd_cert_1_data = pd.DataFrame()\n",
    "snd_cert_1_data[\"data\"] = pd.read_csv(snd_cert_path + \"/snd-cert.1.test\")\n",
    "snd_cert_1_data[\"label\"] = pd.read_csv(snd_cert_path + \"/snd-cert.1.labels\")\n",
    "\n",
    "snd_cert_2_data = pd.DataFrame()\n",
    "snd_cert_2_data[\"data\"] = pd.read_csv(snd_cert_path + \"/snd-cert.2.test\")\n",
    "snd_cert_2_data[\"label\"] = pd.read_csv(snd_cert_path + \"/snd-cert.2.labels\")\n",
    "\n",
    "snd_cert_3_data = pd.DataFrame()\n",
    "snd_cert_3_data[\"data\"] = pd.read_csv(snd_cert_path + \"/snd-cert.3.test\")\n",
    "snd_cert_3_data[\"label\"] = pd.read_csv(snd_cert_path + \"/snd-cert.3.labels\")\n",
    "\n",
    "snd_cert_train_data = pd.DataFrame()\n",
    "snd_cert_train_data[\"data\"] = pd.read_csv(snd_cert_path + \"/snd-cert.train\")\n",
    "snd_cert_train_data[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f65689ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "snd_unm_1_data = pd.DataFrame()\n",
    "snd_unm_1_data[\"data\"] = pd.read_csv(snd_unm_path + \"/snd-unm.1.test\")\n",
    "snd_unm_1_data[\"label\"] = pd.read_csv(snd_unm_path + \"/snd-unm.1.labels\")\n",
    "\n",
    "snd_unm_2_data = pd.DataFrame()\n",
    "snd_unm_2_data[\"data\"] = pd.read_csv(snd_unm_path + \"/snd-unm.2.test\")\n",
    "snd_unm_2_data[\"label\"] = pd.read_csv(snd_unm_path + \"/snd-unm.2.labels\")\n",
    "\n",
    "\n",
    "snd_unm_3_data = pd.DataFrame()\n",
    "snd_unm_3_data[\"data\"] = pd.read_csv(snd_unm_path + \"/snd-unm.3.test\")\n",
    "snd_unm_3_data[\"label\"] = pd.read_csv(snd_unm_path + \"/snd-unm.3.labels\")\n",
    "\n",
    "snd_unm_train_data = pd.DataFrame()\n",
    "snd_unm_train_data[\"data\"] = pd.read_csv(snd_unm_path + \"/snd-unm.train\")\n",
    "snd_unm_train_data[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c6224",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c6cb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_frame(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform any preprocessing steps in a single data frame\n",
    "\n",
    "    We assign a new id column and a new column with the length of the data\n",
    "    \"\"\"\n",
    "    # assign a unique id to each data element so when we split them in substrings, we can then get back to the original\n",
    "    # and conclude about the final class\n",
    "    df[\"id\"] = range(len(df))\n",
    "\n",
    "    df[\"length\"] = df[\"data\"].str.len()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_substrings(df: pd.DataFrame, substr_len: int = 7) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a new dataframe with all the substrings from each row\n",
    "    We will try to get non overlapping substrings, but if the text is not divisible by the desired length, then for the\n",
    "    last substring we will get the last substr_len elements of the string\n",
    "\n",
    "    This method returns a dataframe with the substrings and the label of the original string\n",
    "    \"\"\"\n",
    "    # note for improvement, check the apply method of data frame paired with explode\n",
    "    substr_df = {\"data\": [], \"label\": [], \"id\": []}\n",
    "    for index, row in df.iterrows():\n",
    "        text = row[\"data\"]\n",
    "        label = row[\"label\"]\n",
    "        id = row[\"id\"]\n",
    "        substrings = []\n",
    "        length = row[\"length\"]\n",
    "        start = 0\n",
    "        while start < length:\n",
    "            end = start + substr_len\n",
    "            if end < length:\n",
    "                substrings.append(text[start:end])\n",
    "            else:\n",
    "                substrings.append(text[-substr_len:])\n",
    "            start = end\n",
    "\n",
    "        substr_df[\"data\"].extend(substrings)\n",
    "        substr_df[\"label\"].extend(label for i in range(len(substrings)))\n",
    "        substr_df[\"id\"].extend(id for i in range(len(substrings)))\n",
    "\n",
    "    return pd.DataFrame(substr_df)\n",
    "\n",
    "\n",
    "def preprocess(\n",
    "    df: pd.DataFrame, name: str, data_path: str, is_train: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Apply all the preprocessing steps in a dataframe and save all the resulting dataframes\n",
    "    \"\"\"\n",
    "    df = preprocess_data_frame(df)\n",
    "    df.to_csv(data_path + \"/\" + name + \".csv\")\n",
    "\n",
    "    # extract substrings and save the new dataframe\n",
    "    df_substr = extract_substrings(df)\n",
    "    df_substr.to_csv(data_path + \"/\" + name + \"_substr.csv\")\n",
    "\n",
    "    # save the data in a file to be used in the negative selection algorithm\n",
    "    df_substr[\"data\"].to_csv(\n",
    "        data_path + \"/\" + name + \"_substr\" + (\".train\" if is_train else \".test\"),\n",
    "        header=False,\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d13aa741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_df(df: pd.DataFrame, name: str) -> None:\n",
    "    print(\"Counts for df \" + name)\n",
    "    display(df.groupby(\"length\").count())\n",
    "\n",
    "    print(\"Counts for labels \" + name)\n",
    "    display(df.groupby(\"label\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae02a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse_df(snd_cert_2_data, \"snd_cert_2_data\")\n",
    "# analyse_df(snd_cert_2_data, \"snd_cert_2_data\")\n",
    "# analyse_df(snd_cert_3_data, \"snd_cert_3_data\")\n",
    "\n",
    "# analyse_df(snd_unm_1_data, \"snd_unm_1_data\")\n",
    "# analyse_df(snd_unm_2_data, \"snd_unm_2_data\")\n",
    "# analyse_df(snd_unm_3_data, \"snd_unm_3_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a755fa",
   "metadata": {},
   "source": [
    "Preprocess and save all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6313243e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m preprocess(snd_cert_1_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnd_cert_1\u001b[39m\u001b[38;5;124m\"\u001b[39m, snd_cert_path)\n\u001b[1;32m      2\u001b[0m preprocess(snd_cert_2_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnd_cert_2\u001b[39m\u001b[38;5;124m\"\u001b[39m, snd_cert_path)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnd_cert_3_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msnd_cert_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnd_cert_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m preprocess(snd_cert_train_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnd_cert_train\u001b[39m\u001b[38;5;124m\"\u001b[39m, snd_cert_path, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m preprocess(snd_unm_1_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnd_unm_1\u001b[39m\u001b[38;5;124m\"\u001b[39m, snd_unm_path)\n",
      "Cell \u001b[0;32mIn[6], line 59\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(df, name, data_path, is_train)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# extract substrings and save the new dataframe\u001b[39;00m\n\u001b[1;32m     58\u001b[0m df_substr \u001b[38;5;241m=\u001b[39m extract_substrings(df)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mdf_substr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_substr.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# save the data in a file to be used in the negative selection algorithm\u001b[39;00m\n\u001b[1;32m     62\u001b[0m df_substr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m     63\u001b[0m     data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_substr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.train\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_train \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.test\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     64\u001b[0m     header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     65\u001b[0m     index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     66\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/AI/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/AI/lib/python3.12/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/AI/lib/python3.12/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.pyenv/versions/AI/lib/python3.12/site-packages/pandas/io/formats/csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/AI/lib/python3.12/site-packages/pandas/io/formats/csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/AI/lib/python3.12/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/AI/lib/python3.12/site-packages/pandas/io/formats/csvs.py:324\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[1;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 324\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mwriters.pyx:56\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "preprocess(snd_cert_2_data, \"snd_cert_2\", snd_cert_path)\n",
    "preprocess(snd_cert_2_data, \"snd_cert_2\", snd_cert_path)\n",
    "preprocess(snd_cert_3_data, \"snd_cert_3\", snd_cert_path)\n",
    "preprocess(snd_cert_train_data, \"snd_cert_train\", snd_cert_path, True)\n",
    "\n",
    "preprocess(snd_unm_1_data, \"snd_unm_1\", snd_unm_path)\n",
    "preprocess(snd_unm_2_data, \"snd_unm_2\", snd_unm_path)\n",
    "preprocess(snd_unm_3_data, \"snd_unm_3\", snd_unm_path)\n",
    "preprocess(snd_unm_train_data, \"snd_unm_train\", snd_unm_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72665d14",
   "metadata": {},
   "source": [
    "# Run negative selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c6bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for r in range(1, 8):\n",
    "    for i in range(1, 3):\n",
    "        cmd = (\"java -jar negsel2.jar -alphabet file://data/syscalls/snd-cert/snd-cert.alpha\"\n",
    "            \" -self ./data/syscalls/snd-cert/snd_cert_train_substr.train -n 7 -l -c -r \" + str(r) +\n",
    "            \" < ./data/syscalls/snd-cert/snd_cert_\" + str(i) + \"_substr.test > \"\n",
    "            \"./data/syscalls/snd-cert/snd_cert_\" + str(i) + \"_substr_res_\" + str(r) + \".txt\")\n",
    "        subprocess.run(cmd, capture_output=True, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "83fbbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(1, 8):\n",
    "    cmd = (\"java -jar negsel2.jar -alphabet file://data/syscalls/snd-unm/snd-unm.alpha\"\n",
    "        \" -self ./data/syscalls/snd-unm/snd_unm_train_substr.train -n 7 -l -c -r \" + str(r) +\n",
    "        \" < ./data/syscalls/snd-unm/snd_unm_1_substr.test > \"\n",
    "        \"./data/syscalls/snd-unm/snd_unm_1_substr_res_\" + str(r) + \".txt\")\n",
    "    subprocess.run(cmd, capture_output=True, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb93472",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97f3ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(res_file: str, substr_file: str):\n",
    "    df = pd.DataFrame()\n",
    "    df['score'] = pd.read_csv(res_file)\n",
    "    df['data'] = pd.read_csv(substr_file, usecols=['data'])\n",
    "    df['label'] = pd.read_csv(substr_file, usecols=['label'])\n",
    "    df['id'] = pd.read_csv(substr_file, usecols=['id'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def average_scores(df: pd.DataFrame):\n",
    "    avg_df = df.groupby('id', as_index=False)['score'].mean().reset_index()\n",
    "    df_labels = df.groupby('id')['label'].first().reset_index()\n",
    "    avg_df = pd.merge(avg_df, df_labels, on='id')\n",
    "    avg_df.drop(columns=['index', 'id'], inplace=True)\n",
    "    \n",
    "    return avg_df\n",
    "\n",
    "\n",
    "def calculate_auc(res_file: str, substr_file: str, name: str):\n",
    "    df = load_results(res_file, substr_file)\n",
    "    avg_df = average_scores(df)\n",
    "    auc = metrics.roc_auc_score(avg_df['label'], avg_df['score'])\n",
    "    print(\"AUC for \" + name)\n",
    "    print(auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3f54c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for snd_cert_1_results_1\n",
      "0.7375510204081632\n",
      "AUC for snd_cert_1_results_2\n",
      "0.9408163265306122\n",
      "AUC for snd_cert_1_results_3\n",
      "0.9444897959183673\n",
      "AUC for snd_cert_1_results_4\n",
      "0.9453061224489796\n",
      "AUC for snd_cert_1_results_5\n",
      "0.9448979591836735\n",
      "AUC for snd_cert_1_results_6\n",
      "0.9526530612244898\n",
      "AUC for snd_cert_1_results_7\n",
      "0.9542857142857143\n"
     ]
    }
   ],
   "source": [
    "# cert_1\n",
    "for r in range(1, 8):\n",
    "    res_file = snd_cert_path + '/snd_cert_1_substr_res_' + str(r) + '.txt'\n",
    "    substr_file = snd_cert_path + '/snd_cert_1_substr.csv'\n",
    "    name = 'snd_cert_1_results_' + str(r)\n",
    "    calculate_auc(res_file, substr_file, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "166986f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for snd_cert_2_results_1\n",
      "0.7723446893787576\n",
      "AUC for snd_cert_2_results_2\n",
      "0.948496993987976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for snd_cert_2_results_3\n",
      "0.9657715430861723\n",
      "AUC for snd_cert_2_results_4\n",
      "0.9661322645290581\n",
      "AUC for snd_cert_2_results_5\n",
      "0.9662124248496994\n",
      "AUC for snd_cert_2_results_6\n",
      "0.9670340681362726\n",
      "AUC for snd_cert_2_results_7\n",
      "0.9671342685370741\n"
     ]
    }
   ],
   "source": [
    "# cert_2\n",
    "for r in range(1, 8):\n",
    "    res_file = snd_cert_path + '/snd_cert_2_substr_res_' + str(r) + '.txt'\n",
    "    substr_file = snd_cert_path + '/snd_cert_2_substr.csv'\n",
    "    name = 'snd_cert_2_results_' + str(r)\n",
    "    calculate_auc(res_file, substr_file, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161fcf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unm_1\n",
    "for r in range(1, 8):\n",
    "    res_file = snd_unm_path + '/snd_unm_1_substr_res_' + str(r) + '.txt'\n",
    "    substr_file = snd_unm_path + '/snd_unm_1_substr.csv'\n",
    "    name = 'snd_unm_1_results_' + str(r)\n",
    "    calculate_auc(res_file, substr_file, name)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
