{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a11a79c",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b694d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8308931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "212857ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "snd_cert_path = \"./data/syscalls/snd-cert\"\n",
    "snd_unm_path = \"./data/syscalls/snd-unm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa9bb9",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10032a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "snd_cert_1_data = pd.DataFrame()\n",
    "snd_cert_1_data[\"data\"] = pd.read_csv(snd_cert_path + \"/snd-cert.1.test\")\n",
    "snd_cert_1_data[\"label\"] = pd.read_csv(snd_cert_path + \"/snd-cert.1.labels\")\n",
    "\n",
    "snd_cert_2_data = pd.DataFrame()\n",
    "snd_cert_2_data[\"data\"] = pd.read_csv(snd_cert_path + \"/snd-cert.2.test\")\n",
    "snd_cert_2_data[\"label\"] = pd.read_csv(snd_cert_path + \"/snd-cert.2.labels\")\n",
    "\n",
    "snd_cert_3_data = pd.DataFrame()\n",
    "snd_cert_3_data[\"data\"] = pd.read_csv(snd_cert_path + \"/snd-cert.3.test\")\n",
    "snd_cert_3_data[\"label\"] = pd.read_csv(snd_cert_path + \"/snd-cert.3.labels\")\n",
    "\n",
    "snd_cert_train_data = pd.DataFrame()\n",
    "snd_cert_train_data[\"data\"] = pd.read_csv(snd_cert_path + \"/snd-cert.train\")\n",
    "snd_cert_train_data[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f65689ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "snd_unm_1_data = pd.DataFrame()\n",
    "snd_unm_1_data[\"data\"] = pd.read_csv(snd_unm_path + \"/snd-unm.1.test\")\n",
    "snd_unm_1_data[\"label\"] = pd.read_csv(snd_unm_path + \"/snd-unm.1.labels\")\n",
    "\n",
    "snd_unm_2_data = pd.DataFrame()\n",
    "snd_unm_2_data[\"data\"] = pd.read_csv(snd_unm_path + \"/snd-unm.2.test\")\n",
    "snd_unm_2_data[\"label\"] = pd.read_csv(snd_unm_path + \"/snd-unm.2.labels\")\n",
    "\n",
    "\n",
    "snd_unm_3_data = pd.DataFrame()\n",
    "snd_unm_3_data[\"data\"] = pd.read_csv(snd_unm_path + \"/snd-unm.3.test\")\n",
    "snd_unm_3_data[\"label\"] = pd.read_csv(snd_unm_path + \"/snd-unm.3.labels\")\n",
    "\n",
    "snd_unm_train_data = pd.DataFrame()\n",
    "snd_unm_train_data[\"data\"] = pd.read_csv(snd_unm_path + \"/snd-unm.train\")\n",
    "snd_unm_train_data[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c6224",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c6cb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_frame(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform any preprocessing steps in a single data frame\n",
    "\n",
    "    We assign a new id column and a new column with the length of the data\n",
    "    \"\"\"\n",
    "    # assign a unique id to each data element so when we split them in substrings, we can then get back to the original\n",
    "    # and conclude about the final class\n",
    "    df[\"id\"] = range(len(df))\n",
    "\n",
    "    df[\"length\"] = df[\"data\"].str.len()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_substrings(df: pd.DataFrame, substr_len: int = 7) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a new dataframe with all the substrings from each row\n",
    "    We will try to get non overlapping substrings, but if the text is not divisible by the desired length, then for the\n",
    "    last substring we will get the last substr_len elements of the string\n",
    "\n",
    "    This method returns a dataframe with the substrings and the label of the original string\n",
    "    \"\"\"\n",
    "    # note for improvement, check the apply method of data frame paired with explode\n",
    "    substr_df = {\"data\": [], \"label\": [], \"id\": []}\n",
    "    for index, row in df.iterrows():\n",
    "        text = row[\"data\"]\n",
    "        label = row[\"label\"]\n",
    "        id = row[\"id\"]\n",
    "        substrings = []\n",
    "        length = row[\"length\"]\n",
    "        start = 0\n",
    "        while start < length:\n",
    "            end = start + substr_len\n",
    "            if end < length:\n",
    "                substrings.append(text[start:end])\n",
    "            else:\n",
    "                substrings.append(text[-substr_len:])\n",
    "            start = end\n",
    "\n",
    "        substr_df[\"data\"].extend(substrings)\n",
    "        substr_df[\"label\"].extend(label for i in range(len(substrings)))\n",
    "        substr_df[\"id\"].extend(id for i in range(len(substrings)))\n",
    "\n",
    "    return pd.DataFrame(substr_df)\n",
    "\n",
    "\n",
    "def preprocess(\n",
    "    df: pd.DataFrame, name: str, data_path: str, is_train: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Apply all the preprocessing steps in a dataframe and save all the resulting dataframes\n",
    "    \"\"\"\n",
    "    df = preprocess_data_frame(df)\n",
    "    df.to_csv(data_path + \"/\" + name + \".csv\")\n",
    "\n",
    "    # extract substrings and save the new dataframe\n",
    "    df_substr = extract_substrings(df)\n",
    "    df_substr.to_csv(data_path + \"/\" + name + \"_substr.csv\")\n",
    "\n",
    "    # save the data in a file to be used in the negative selection algorithm\n",
    "    df_substr[\"data\"].to_csv(\n",
    "        data_path + \"/\" + name + \"_substr\" + (\".train\" if is_train else \".test\"),\n",
    "        header=False,\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d13aa741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_df(df: pd.DataFrame, name: str) -> None:\n",
    "    print(\"Counts for df \" + name)\n",
    "    display(df.groupby(\"length\").count())\n",
    "\n",
    "    print(\"Counts for labels \" + name)\n",
    "    display(df.groupby(\"label\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae02a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse_df(snd_cert_1_data, \"snd_cert_1_data\")\n",
    "# analyse_df(snd_cert_2_data, \"snd_cert_2_data\")\n",
    "# analyse_df(snd_cert_3_data, \"snd_cert_3_data\")\n",
    "\n",
    "# analyse_df(snd_unm_1_data, \"snd_unm_1_data\")\n",
    "# analyse_df(snd_unm_2_data, \"snd_unm_2_data\")\n",
    "# analyse_df(snd_unm_3_data, \"snd_unm_3_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a755fa",
   "metadata": {},
   "source": [
    "Preprocess and save all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6313243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocess(snd_cert_1_data, \"snd_cert_1\", snd_cert_path)\n",
    "preprocess(snd_cert_2_data, \"snd_cert_2\", snd_cert_path)\n",
    "preprocess(snd_cert_3_data, \"snd_cert_3\", snd_cert_path)\n",
    "preprocess(snd_cert_train_data, \"snd_cert_train\", snd_cert_path, True)\n",
    "\n",
    "preprocess(snd_unm_1_data, \"snd_unm_1\", snd_unm_path)\n",
    "preprocess(snd_unm_2_data, \"snd_unm_2\", snd_unm_path)\n",
    "preprocess(snd_unm_3_data, \"snd_unm_3\", snd_unm_path)\n",
    "preprocess(snd_unm_train_data, \"snd_unm_train\", snd_unm_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72665d14",
   "metadata": {},
   "source": [
    "# Run negative selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c6bb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='java -jar negsel2.jar -alphabet file://data/syscalls/snd-cert/snd-cert.alpha -self ./data/syscalls/snd-cert/snd_cert_train_substr.train -n 7 -l -c -r 1  < ./data/syscalls/snd-cert/snd_cert_1_substr.test > ./data/syscalls/snd-cert/snd_cert_1_substr_res.txt', returncode=0, stdout=b'', stderr=b'')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    \"java -jar negsel2.jar -alphabet file://data/syscalls/snd-cert/snd-cert.alpha\"\n",
    "    \" -self ./data/syscalls/snd-cert/snd_cert_train_substr.train -n 7 -l -c -r 1 \"\n",
    "    \" < ./data/syscalls/snd-cert/snd_cert_1_substr.test > ./data/syscalls/snd-cert/snd_cert_1_substr_res.txt\",\n",
    "    capture_output=True, shell=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb93472",
   "metadata": {},
   "source": [
    "# Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "08d8f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
