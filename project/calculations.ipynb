{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random_dataset import create_random_dataset\n",
    "from evolutionary_algorithm import EA\n",
    "from greedy_algorithm import GreedyAlgorithm\n",
    "from neg_sel import NegativeSelection, load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_peptides_data_dir = \"./data/sampled/\"\n",
    "peptides_data_dir = \"./data/peptides/\"\n",
    "\n",
    "self1_data = pd.read_csv(peptides_data_dir + \"self1-6mers.txt\", header=None)\n",
    "\n",
    "self1_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dataset = create_random_dataset(df=self1_data, n=2000, seed=42)\n",
    "\n",
    "random_dataset_list = random_dataset[0].to_list()\n",
    "random_dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sampled_peptides_data_dir + \"self1_6mers_random.txt\", \"w\") as f:\n",
    "    for item in random_dataset_list:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peptide Preperations and Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides = self1_data[0].tolist()\n",
    "peptide_length = len(peptides[0])\n",
    "\n",
    "position_counts = [defaultdict(int) for _ in range(peptide_length)]\n",
    "\n",
    "# count frequencies per position\n",
    "for peptide in peptides:\n",
    "    for i, aa in enumerate(peptide):\n",
    "        position_counts[i][aa] += 1\n",
    "\n",
    "# convert counts to frequencies\n",
    "position_freqs = []\n",
    "for pos in position_counts:\n",
    "    total = sum(pos.values())\n",
    "    pos_freq = {aa: count / total for aa, count in pos.items()}\n",
    "    position_freqs.append(pos_freq)\n",
    "\n",
    "\n",
    "def compute_Fpep(peptide, position_freqs):\n",
    "    return sum(position_freqs[i].get(aa, 0) for i, aa in enumerate(peptide))\n",
    "\n",
    "\n",
    "fpep_scores = [compute_Fpep(p, position_freqs) for p in peptides]\n",
    "\n",
    "fpep_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "\n",
    "motifs = [\"\".join(motif) for motif in product(amino_acids, repeat=6)]\n",
    "\n",
    "print(f\"Total number of motifs: {len(motifs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self1_data[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# greedy_optimizer = GreedyAlgorithm(\n",
    "#     peptides=self1_data[0].tolist(),\n",
    "#     motifs=motifs,\n",
    "#     t=3,\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# for now, let's limit the lists due to computational constraints\n",
    "greedy_optimizer = GreedyAlgorithm(peptides=self1_data[0].tolist()[0:200], motifs=motifs[0:200000], t=3, seed=42)\n",
    "self1_optimized_data = greedy_optimizer.run()\n",
    "self1_optimized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Size of greedily optimized data set: {len(self1_optimized_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sampled_peptides_data_dir + \"self1_6mers_greedy.txt\", \"w\") as f:\n",
    "    for item in self1_optimized_data:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Evolutionary Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides = self1_data[0].tolist() # [0:200] test\n",
    "peptide_length = len(peptides[0])\n",
    "\n",
    "position_counts = [defaultdict(int) for _ in range(peptide_length)]\n",
    "\n",
    "# count frequencies per position\n",
    "for peptide in peptides:\n",
    "    for i, aa in enumerate(peptide):\n",
    "        position_counts[i][aa] += 1\n",
    "\n",
    "# convert counts to frequencies\n",
    "position_freqs = []\n",
    "for pos in position_counts:\n",
    "    total = sum(pos.values())\n",
    "    pos_freq = {aa: count / total for aa, count in pos.items()}\n",
    "    position_freqs.append(pos_freq)\n",
    "\n",
    "\n",
    "def compute_Fpep(peptide):\n",
    "    return sum(position_freqs[i].get(aa, 0) for i, aa in enumerate(peptide))\n",
    "\n",
    "\n",
    "def compute_aa_frequency_scores(peptides):\n",
    "    aa_counts = defaultdict(int)\n",
    "    total_aa = 0\n",
    "\n",
    "    for p in peptides:\n",
    "        for aa in p:\n",
    "            aa_counts[aa] += 1\n",
    "            total_aa += 1\n",
    "\n",
    "    aa_freqs = {aa: count / total_aa for aa, count in aa_counts.items()}\n",
    "\n",
    "    def score(peptide):\n",
    "        return sum(aa_freqs[aa] for aa in peptide)\n",
    "\n",
    "    return [score(p) for p in peptides]\n",
    "\n",
    "\n",
    "aa_freq_scores = compute_aa_frequency_scores(peptides)\n",
    "\n",
    "feature_vectors = []\n",
    "for i, peptide in enumerate(peptides):\n",
    "    fpep = compute_Fpep(peptide)\n",
    "    aa = aa_freq_scores[i]\n",
    "    feature_vectors.append([fpep, aa])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "feature_vectors = scaler.fit_transform(feature_vectors)\n",
    "\n",
    "def affinity(motif: str, peptide: str) -> int:\n",
    "    max_adjacent = 0\n",
    "    current = 0\n",
    "    for m, p in zip(motif, peptide):\n",
    "        if m == p:\n",
    "            current += 1\n",
    "            if current > max_adjacent:\n",
    "                max_adjacent = current\n",
    "        else:\n",
    "            current = 0\n",
    "    return max_adjacent\n",
    "\n",
    "def compute_exchangeability(subset_peptides, t):\n",
    "    n = len(subset_peptides)\n",
    "    scores = np.zeros(n, dtype=int)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j and affinity(subset_peptides[i], subset_peptides[j]) >= t:\n",
    "                scores[i] += 1\n",
    "\n",
    "    return scores\n",
    "\n",
    "t = 3 # threshold affinity\n",
    "exchangeability_mean_global = np.mean(compute_exchangeability(peptides, t))\n",
    "def composite_fitness(indices):\n",
    "    subset_vectors = feature_vectors[indices]\n",
    "    subset_peptides = [peptides[i] for i in indices]\n",
    "    \n",
    "    fpep_mean = np.mean(subset_vectors[:, 0])\n",
    "    aa_mean = np.mean(subset_vectors[:, 1])\n",
    "    \n",
    "    exchangeability_scores = compute_exchangeability(subset_peptides, t)\n",
    "    exchangeability_mean = np.mean(exchangeability_scores)\n",
    "    exchangeability_norm = exchangeability_mean / exchangeability_mean_global\n",
    "\n",
    "    return 1 * fpep_mean + 1 * aa_mean + 1 * exchangeability_norm\n",
    "\n",
    "\n",
    "m_ea = EA(data=feature_vectors, N=100, sigma=30, K=2, p=0.1, mu=0.02, T=1000, f=composite_fitness, seed=42)\n",
    "multi_best_individual, multi_best_fitness, multi_fitness_avg, multi_fitness_best = m_ea.run()\n",
    "\n",
    "plt.plot(multi_fitness_best, label=\"Best Fitness (Multi Fitness function, f_pep, aas freq, exch)\")\n",
    "plt.plot(multi_fitness_avg, label=\"Avg Fitness (Multi Fitness function, f_pep, aas freq, exch)\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.title(\"EA Progress\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "multi_optimal_peptides = [peptides[i] for i in multi_best_individual]\n",
    "multi_optimal_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sampled_peptides_data_dir + \"self1_6mers_ea_impr.txt\", \"w\") as f:\n",
    "    for item in multi_optimal_peptides:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_start = 1\n",
    "r_stop = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = NegativeSelection(\n",
    "    \"/data/sampled/6mers.alpha\", \"./data/sampled/self1_6mers_random.txt\", r_start=r_start, r_stop=r_stop\n",
    ")\n",
    "\n",
    "ns.run(\"./data/peptides/ebola-6mers.txt\")\n",
    "ns.run(\"./data/peptides/self2-6mers.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate metrics of negative selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data: pd.DataFrame, r: int):\n",
    "    anomalous_data = data[data[\"anomalous\"] == 1]\n",
    "    sensitivity = len(anomalous_data[anomalous_data[\"score\"] > r]) / len(anomalous_data)\n",
    "\n",
    "    non_anomalous_data = data[data[\"anomalous\"] == 0]\n",
    "    specificity = len(non_anomalous_data[non_anomalous_data[\"score\"] < r]) / len(non_anomalous_data)\n",
    "\n",
    "    data[\"y\"] = data[\"score\"] > r\n",
    "\n",
    "    return anomalous_data, non_anomalous_data, data\n",
    "\n",
    "\n",
    "def caclulate_roc_auc(data):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(data[\"anomalous\"], data[\"score\"])\n",
    "    auc = metrics.roc_auc_score(data[\"anomalous\"], data[\"score\"])\n",
    "    roc = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc)\n",
    "\n",
    "    return auc, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = \"./data/results\"\n",
    "pd.set_option('future.no_silent_downcasting', True) # opt-in for future behavior of replace\n",
    "\n",
    "fig, ax = plt.subplots(1, r_stop, figsize=(10, 10), constrained_layout=True)\n",
    "\n",
    "acc_list = []\n",
    "err_rate_list = []\n",
    "f1_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "for r in range(r_start, r_stop + 1):\n",
    "    anomalous_data = load_data(\"./data/peptides/ebola-6mers.txt\", r, 1)\n",
    "    normal_data = load_data(\"./data/peptides/self2-6mers.txt\", r, 0)\n",
    "    data = pd.concat([anomalous_data, normal_data])\n",
    "\n",
    "    _, _, data = preprocess_data(data, r)\n",
    "    # display(data.head())\n",
    "\n",
    "    auc, roc = caclulate_roc_auc(data)\n",
    "    axis = ax[r - 1]\n",
    "    roc.plot(ax=axis)\n",
    "    axis.set_title(f\"r={r}\")\n",
    "\n",
    "\n",
    "    y_true = data['anomalous'].to_list()\n",
    "    y_pred = data['y'].replace({True: 1, False: 0}).to_list()\n",
    "    acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    err_rate = 1 - acc\n",
    "\n",
    "    f1 = metrics.f1_score(y_true, y_pred)\n",
    "    precision = metrics.precision_score(y_true, y_pred)\n",
    "    recall = metrics.recall_score(y_true, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    err_rate_list.append(err_rate)\n",
    "    f1_list.append(f1)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_values = [r for r in range(r_start, r_stop + 1)]\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(r_values))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(x, acc_list, bar_width, label='Accuracy', color='green')\n",
    "plt.bar(x + bar_width, err_rate_list, bar_width, label='Error Rate', color='red')\n",
    "\n",
    "# Add trend lines for accuracy and error rates\n",
    "# Use moving average for the trend line (smooth line)\n",
    "window = 1  # Number of points to average over\n",
    "accuracy_trend = np.convolve(acc_list, np.ones(window)/window, mode='valid')\n",
    "error_trend = np.convolve(err_rate_list, np.ones(window)/window, mode='valid')\n",
    "\n",
    "plt.plot(x[window-1:], accuracy_trend, 'g--', label='Accuracy Trend')\n",
    "plt.plot(x[window-1:], error_trend, 'r--', label='Error Rate Trend')\n",
    "\n",
    "plt.xlabel('Parameter r')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Accuracy vs. Error Rate for Different r Values')\n",
    "plt.xticks(x + bar_width / 2, r_values)  # Center the x-tick labels\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_width = 0.25\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "fig, ax = plt.subplots(layout='constrained', figsize=(10, 6))\n",
    "\n",
    "ax.bar(x, f1_list, bar_width, label='F1 Score', color='blue')\n",
    "ax.bar(x + bar_width, precision_list, bar_width, label='Precision', color='yellow')\n",
    "ax.bar(x + 2*bar_width, recall_list, bar_width, label='Recall', color='orange')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Parameter r')\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('F1 Score, Precision and Recall for Different r Values')\n",
    "ax.legend()\n",
    "ax.set_xticks(x + bar_width, r_values)\n",
    "ax.grid(True, alpha=0.2)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
